"""
CliCare Objective 1 - Department Assignment Integration Testing (COMPREHENSIVE ENHANCED)
Run: python test1_department.py
"""

import requests
import pandas as pd
import numpy as np
from collections import defaultdict
import json
import time
from datetime import datetime, timedelta
import os
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sns

# ============================================================================
# CONFIGURATION
# ============================================================================

API_BASE = "http://localhost:5000"
OUTPUT_DIR = "objective1_comprehensive_results/department_assignment"

# Test configuration
COMPREHENSIVE_TEST = True
CLEANUP_AFTER_TEST = True

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def create_output_directory():
    """Create output directory for test results"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

def print_section_header(title):
    """Print formatted section header"""
    print("\n" + "="*80)
    print(title.center(80))
    print("="*80 + "\n")

def make_api_request(endpoint, method="GET", data=None, headers=None):
    """Make API request with error handling"""
    try:
        url = f"{API_BASE}/{endpoint}"
        
        if method == "GET":
            response = requests.get(url, headers=headers, timeout=15)
        elif method == "POST":
            response = requests.post(url, json=data, headers=headers, timeout=15)
        elif method == "DELETE":
            response = requests.delete(url, json=data, headers=headers, timeout=15)
        
        if response.status_code in [200, 201]:
            return response.json()
        else:
            print(f"‚ö†Ô∏è  API Error: {response.status_code} - {response.text[:200]}")
            return None
    except requests.exceptions.Timeout:
        print(f"‚ö†Ô∏è  Request timeout for {endpoint}")
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è  Request failed: {e}")
        return None

def print_statistics_computation(dept_metrics, y_true, y_pred):
    """Print detailed statistical computations with formulas"""
    print_section_header("STATISTICAL COMPUTATIONS")
    
    # Calculate overall statistics
    total_samples = len(y_true)
    total_tp = sum(m['tp'] for m in dept_metrics)
    total_fp = sum(m['fp'] for m in dept_metrics)
    total_fn = sum(m['fn'] for m in dept_metrics)
    total_tn = sum(m['tn'] for m in dept_metrics)
    
    # Overall metrics
    accuracy = (total_tp / total_samples * 100) if total_samples > 0 else 0
    precision = (total_tp / (total_tp + total_fp) * 100) if (total_tp + total_fp) > 0 else 0
    recall = (total_tp / (total_tp + total_fn) * 100) if (total_tp + total_fn) > 0 else 0
    f1_score = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0
    
    print("üìä OVERALL METRICS COMPUTATION")
    print("="*80)
    print(f"\n1. ACCURACY (Overall Classification Correctness)")
    print(f"   Formula: (TP + TN) / (TP + TN + FP + FN) √ó 100")
    print(f"   Computation: ({total_tp} + {total_tn}) / ({total_tp} + {total_tn} + {total_fp} + {total_fn}) √ó 100")
    print(f"   Computation: {total_tp + total_tn} / {total_samples} √ó 100")
    print(f"   Result: {accuracy:.2f}%")
    print(f"   Interpretation: {'‚úÖ PASS' if accuracy >= 85 else '‚ùå FAIL'} (Target: ‚â•85%)")
    
    print(f"\n2. PRECISION (Positive Predictive Value)")
    print(f"   Formula: TP / (TP + FP) √ó 100")
    print(f"   Computation: {total_tp} / ({total_tp} + {total_fp}) √ó 100")
    print(f"   Computation: {total_tp} / {total_tp + total_fp} √ó 100")
    print(f"   Result: {precision:.2f}%")
    print(f"   Interpretation: {'‚úÖ PASS' if precision >= 80 else '‚ùå FAIL'} (Target: ‚â•80%)")
    print(f"   Meaning: Of all patients assigned to a department, {precision:.1f}% were correctly assigned")
    
    print(f"\n3. RECALL (Sensitivity/True Positive Rate)")
    print(f"   Formula: TP / (TP + FN) √ó 100")
    print(f"   Computation: {total_tp} / ({total_tp} + {total_fn}) √ó 100")
    print(f"   Computation: {total_tp} / {total_tp + total_fn} √ó 100")
    print(f"   Result: {recall:.2f}%")
    print(f"   Interpretation: {'‚úÖ PASS' if recall >= 85 else '‚ùå FAIL'} (Target: ‚â•85%)")
    print(f"   Meaning: Of all patients that should go to a department, {recall:.1f}% were correctly identified")
    
    print(f"\n4. F1-SCORE (Harmonic Mean of Precision and Recall)")
    print(f"   Formula: 2 √ó (Precision √ó Recall) / (Precision + Recall)")
    print(f"   Computation: 2 √ó ({precision:.2f} √ó {recall:.2f}) / ({precision:.2f} + {recall:.2f})")
    print(f"   Computation: 2 √ó {precision * recall:.2f} / {precision + recall:.2f}")
    print(f"   Result: {f1_score:.2f}%")
    print(f"   Interpretation: {'‚úÖ PASS' if f1_score >= 82 else '‚ùå FAIL'} (Target: ‚â•82%)")
    print(f"   Meaning: Balanced measure between precision and recall")
    
    print("\n" + "="*80)
    print("üìä PER-DEPARTMENT METRICS")
    print("="*80)
    
    for idx, metric in enumerate(dept_metrics, 1):
        dept = metric['department']
        tp = metric['tp']
        fp = metric['fp']
        fn = metric['fn']
        tn = metric['tn']
        prec = metric['precision']
        rec = metric['recall']
        f1 = metric['f1_score']
        
        print(f"\n{idx}. {dept.upper()}")
        print(f"   {'‚îÄ'*70}")
        print(f"   True Positives (TP):  {tp:3d} - Correctly assigned to {dept}")
        print(f"   False Positives (FP): {fp:3d} - Incorrectly assigned to {dept}")
        print(f"   False Negatives (FN): {fn:3d} - Should be {dept} but assigned elsewhere")
        print(f"   True Negatives (TN):  {tn:3d} - Correctly NOT assigned to {dept}")
        print(f"   {'‚îÄ'*70}")
        print(f"   Precision: {tp}/{tp+fp} √ó 100 = {prec:.2f}%")
        print(f"   Recall:    {tp}/{tp+fn} √ó 100 = {rec:.2f}%")
        print(f"   F1-Score:  {f1:.2f}%")
    
    print("\n" + "="*80)
    print("üìà CONFUSION MATRIX LEGEND")
    print("="*80)
    print("   TP (True Positive):   System correctly assigns patient to the right department")
    print("   FP (False Positive):  System assigns patient to wrong department")
    print("   FN (False Negative):  System fails to assign patient to correct department")
    print("   TN (True Negative):   System correctly does NOT assign to wrong department")
    print("="*80)

def generate_department_assignment_test_cases():
    """Generate comprehensive test cases for department assignment"""
    
    test_cases = [
        # ENT and Ophthalmology - 5 cases
        {"symptoms": ["Ear Pain"], "expected": "ENT and Ophthalmology", "age": 25, "category": "ENT"},
        {"symptoms": ["Hearing Loss"], "expected": "ENT and Ophthalmology", "age": 50, "category": "ENT"},
        {"symptoms": ["Vision Problems"], "expected": "ENT and Ophthalmology", "age": 35, "category": "Ophthalmology"},
        {"symptoms": ["Eye Redness"], "expected": "ENT and Ophthalmology", "age": 32, "category": "Ophthalmology"},
        {"symptoms": ["Sinusitis"], "expected": "ENT and Ophthalmology", "age": 30, "category": "ENT"},
        
        # Obstetrics and Gynecology - 4 cases
        {"symptoms": ["Irregular Menstruation"], "expected": "Obstetrics and Gynecology", "age": 25, "category": "Gynecology"},
        {"symptoms": ["Pregnancy Check-up"], "expected": "Obstetrics and Gynecology", "age": 28, "category": "Obstetrics"},
        {"symptoms": ["Prenatal Care"], "expected": "Obstetrics and Gynecology", "age": 30, "category": "Obstetrics"},
        {"symptoms": ["Pelvic Pain"], "expected": "Obstetrics and Gynecology", "age": 26, "category": "Gynecology"},
        
        # General Surgery - 4 cases
        {"symptoms": ["Suspected Appendicitis"], "expected": "General Surgery", "age": 25, "category": "Emergency Surgery"},
        {"symptoms": ["Hernia"], "expected": "General Surgery", "age": 40, "category": "Elective Surgery"},
        {"symptoms": ["Gallstones"], "expected": "General Surgery", "age": 45, "category": "Hepatobiliary"},
        {"symptoms": ["Abscess"], "expected": "General Surgery", "age": 30, "category": "Infection"},
        
        # Pediatrics - 4 cases
        {"symptoms": ["Fever (Child)"], "expected": "Pediatrics", "age": 5, "category": "Pediatric General"},
        {"symptoms": ["Cough and Colds (Child)"], "expected": "Pediatrics", "age": 8, "category": "Pediatric Respiratory"},
        {"symptoms": ["Vaccination"], "expected": "Pediatrics", "age": 2, "category": "Preventive Care"},
        {"symptoms": ["Ear Pain (Child)"], "expected": "Pediatrics", "age": 6, "category": "Pediatric ENT"},
        
        # Family Medicine Regular - 5 cases
        {"symptoms": ["Fever"], "expected": "Family Medicine Regular", "age": 25, "category": "General Medicine"},
        {"symptoms": ["Headache"], "expected": "Family Medicine Regular", "age": 30, "category": "General Medicine"},
        {"symptoms": ["Cough"], "expected": "Family Medicine Regular", "age": 35, "category": "Respiratory"},
        {"symptoms": ["Annual Check-up"], "expected": "Family Medicine Regular", "age": 40, "category": "Routine Care"},
        {"symptoms": ["Fatigue"], "expected": "Family Medicine Regular", "age": 32, "category": "General Medicine"},
        
        # Family Medicine Senior/PWD - 3 cases
        {"symptoms": ["Senior Check-up"], "expected": "Family Medicine Senior/PWD", "age": 65, "category": "Senior Care"},
        {"symptoms": ["Blood Pressure Check"], "expected": "Family Medicine Senior/PWD", "age": 70, "category": "Senior Care"},
        {"symptoms": ["Diabetes Monitoring"], "expected": "Family Medicine Senior/PWD", "age": 68, "category": "Senior Care"},
        
        # Internal Medicine - 5 cases
        {"symptoms": ["Chest Discomfort"], "expected": "Cardiology", "age": 45, "category": "Cardiovascular"},
        {"symptoms": ["High Blood Pressure"], "expected": "Internal Medicine", "age": 50, "category": "Cardiovascular"},
        {"symptoms": ["Diabetes"], "expected": "Internal Medicine", "age": 55, "category": "Endocrine"},
        {"symptoms": ["Shortness of Breath"], "expected": "Internal Medicine", "age": 48, "category": "Respiratory"},
        {"symptoms": ["Stomach Pain"], "expected": "Internal Medicine", "age": 40, "category": "Gastrointestinal"},
        
        # TB DOTS - 3 cases
        {"symptoms": ["Persistent Cough"], "expected": "TB DOTS", "age": 35, "category": "Respiratory"},
        {"symptoms": ["Night Sweats"], "expected": "TB DOTS", "age": 40, "category": "TB Symptoms"},
        {"symptoms": ["Unexplained Weight Loss"], "expected": "TB DOTS", "age": 38, "category": "TB Symptoms"},
        
        # Dental - 4 cases
        {"symptoms": ["Toothache"], "expected": "Dental", "age": 25, "category": "Dental Pain"},
        {"symptoms": ["Gum Bleeding"], "expected": "Dental", "age": 35, "category": "Periodontal"},
        {"symptoms": ["Tooth Decay"], "expected": "Dental", "age": 20, "category": "Restorative"},
        {"symptoms": ["Oral Infection"], "expected": "Dental", "age": 30, "category": "Oral Pathology"},
        
        # SUBSPECIALTY DEPARTMENTS
        
        # Diabetes Clinic - 2 cases
        {"symptoms": ["Diabetes Management"], "expected": "Diabetes Clinic", "age": 50, "category": "Endocrine"},
        {"symptoms": ["High Blood Sugar"], "expected": "Diabetes Clinic", "age": 55, "category": "Endocrine"},
        
        # Cardiology - 3 cases
        {"symptoms": ["Heart Disease"], "expected": "Cardiology", "age": 60, "category": "Cardiovascular"},
        {"symptoms": ["Irregular Heartbeat"], "expected": "Cardiology", "age": 58, "category": "Cardiovascular"},
        {"symptoms": ["Heart Attack History"], "expected": "Cardiology", "age": 65, "category": "Cardiovascular"},
        
        # Nephrology Adult - 2 cases
        {"symptoms": ["Kidney Disease"], "expected": "Nephrology Adult", "age": 55, "category": "Renal Care"},
        {"symptoms": ["Abnormal Creatinine Levels"], "expected": "Nephrology Adult", "age": 50, "category": "Renal Function"},
        
        # Pulmonology Adult - 2 cases
        {"symptoms": ["Asthma"], "expected": "Pulmonology Adult", "age": 40, "category": "Respiratory"},
        {"symptoms": ["COPD"], "expected": "Pulmonology Adult", "age": 65, "category": "Respiratory"},
        
        # Neurology - 2 cases
        {"symptoms": ["Seizure Disorder/Epilepsy"], "expected": "Neurology", "age": 35, "category": "Neurological"},
        {"symptoms": ["Migraine"], "expected": "Neurology", "age": 30, "category": "Neurological"},
        
        # Gastroenterology Adult - 2 cases
        {"symptoms": ["Chronic Abdominal Pain"], "expected": "Gastroenterology Adult", "age": 40, "category": "GI Procedures"},
        {"symptoms": ["Chronic/Recurrent Black Stool"], "expected": "Gastroenterology Adult", "age": 45, "category": "GI Bleeding"},
    ]
    
    return test_cases

def create_enhanced_confusion_matrix(cm, departments, output_path):
    """Create enhanced confusion matrix visualization matching uploaded image style"""
    
    # Set up the figure with the exact style from the image
    fig, ax = plt.subplots(figsize=(16, 14))
    
    # Create the confusion matrix heatmap with specific colors
    # Using teal/turquoise colors like in the uploaded image
    cmap_colors = ['#B2DFDB', '#80CBC4', '#4DB6AC', '#26A69A']  # Light to dark teal
    
    # Normalize values for color mapping
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    # Create custom colormap
    from matplotlib.colors import LinearSegmentedColormap
    custom_cmap = LinearSegmentedColormap.from_list('custom_teal', 
                                                     ['#E0F2F1', '#B2DFDB', '#80CBC4', '#4DB6AC', '#26A69A'])
    
    # Plot heatmap
    im = ax.imshow(cm, interpolation='nearest', cmap=custom_cmap, aspect='auto')
    
    # Configure axes
    ax.set_xticks(np.arange(len(departments)))
    ax.set_yticks(np.arange(len(departments)))
    ax.set_xticklabels(departments, rotation=45, ha='right', fontsize=10)
    ax.set_yticklabels(departments, fontsize=10)
    
    # Add labels
    ax.set_xlabel('Predicted Department', fontsize=14, fontweight='bold', labelpad=10)
    ax.set_ylabel('Actual Department', fontsize=14, fontweight='bold', labelpad=10)
    ax.set_title('Confusion Matrix - Department Assignment System', 
                 fontsize=16, fontweight='bold', pad=20)
    
    # Add text annotations
    thresh = cm.max() / 2.
    for i in range(len(departments)):
        for j in range(len(departments)):
            text_color = 'white' if cm[i, j] > thresh else 'black'
            text = ax.text(j, i, f'{cm[i, j]}',
                          ha="center", va="center", color=text_color,
                          fontsize=11, fontweight='bold')
    
    # Add colorbar
    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label('Number of Cases', rotation=270, labelpad=20, fontsize=12, fontweight='bold')
    
    # Add grid
    ax.set_xticks(np.arange(len(departments))-.5, minor=True)
    ax.set_yticks(np.arange(len(departments))-.5, minor=True)
    ax.grid(which="minor", color="gray", linestyle='-', linewidth=1)
    ax.tick_params(which="minor", size=0)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Enhanced confusion matrix visualization saved to {output_path}")

def create_binary_confusion_matrix_diagram(output_path):
    """Create the 2x2 binary confusion matrix diagram like in the uploaded image"""
    
    fig, ax = plt.subplots(figsize=(10, 8))
    ax.set_xlim(0, 10)
    ax.set_ylim(0, 10)
    ax.axis('off')
    
    # Define colors matching the uploaded image
    tp_color = '#4DB6AC'  # Darker teal for TP
    fn_color = '#80CBC4'  # Medium teal for FN
    fp_color = '#B2DFDB'  # Light teal for FP
    tn_color = '#E0F2F1'  # Very light teal for TN
    
    # Draw the 2x2 grid boxes
    box_size = 3.5
    start_x = 2.5
    start_y = 2
    
    # TP box (top-left)
    tp_rect = mpatches.Rectangle((start_x, start_y + box_size), box_size, box_size, 
                                  linewidth=2, edgecolor='black', facecolor=tp_color)
    ax.add_patch(tp_rect)
    ax.text(start_x + box_size/2, start_y + box_size + box_size/2, 
            'TP\n(True Positive)', ha='center', va='center', 
            fontsize=16, fontweight='bold', color='white')
    
    # FN box (top-right)
    fn_rect = mpatches.Rectangle((start_x + box_size, start_y + box_size), box_size, box_size, 
                                  linewidth=2, edgecolor='black', facecolor=fn_color)
    ax.add_patch(fn_rect)
    ax.text(start_x + box_size + box_size/2, start_y + box_size + box_size/2, 
            'FN\n(False Negative)', ha='center', va='center', 
            fontsize=16, fontweight='bold', color='white')
    
    # FP box (bottom-left)
    fp_rect = mpatches.Rectangle((start_x, start_y), box_size, box_size, 
                                  linewidth=2, edgecolor='black', facecolor=fp_color)
    ax.add_patch(fp_rect)
    ax.text(start_x + box_size/2, start_y + box_size/2, 
            'FP\n(False Positive)', ha='center', va='center', 
            fontsize=16, fontweight='bold', color='black')
    
    # TN box (bottom-right)
    tn_rect = mpatches.Rectangle((start_x + box_size, start_y), box_size, box_size, 
                                  linewidth=2, edgecolor='black', facecolor=tn_color)
    ax.add_patch(tn_rect)
    ax.text(start_x + box_size + box_size/2, start_y + box_size/2, 
            'TN\n(True Negative)', ha='center', va='center', 
            fontsize=16, fontweight='bold', color='black')
    
    # Add labels
    # Title
    ax.text(5, 9.2, 'Predicted Department', ha='center', va='center', 
            fontsize=18, fontweight='bold')
    
    # Column headers
    ax.text(start_x + box_size/2, start_y + 2*box_size + 0.3, 'Positive', 
            ha='center', va='bottom', fontsize=14, fontweight='bold')
    ax.text(start_x + box_size + box_size/2, start_y + 2*box_size + 0.3, 'Negative', 
            ha='center', va='bottom', fontsize=14, fontweight='bold')
    
    # Row label (rotated)
    ax.text(start_x - 0.5, start_y + box_size/2, 'Negative', 
            ha='right', va='center', fontsize=14, fontweight='bold', rotation=90)
    ax.text(start_x - 0.5, start_y + box_size + box_size/2, 'Positive', 
            ha='right', va='center', fontsize=14, fontweight='bold', rotation=90)
    
    # Y-axis label
    ax.text(start_x - 1.2, start_y + box_size, 'Actual Department', 
            ha='center', va='center', fontsize=18, fontweight='bold', rotation=90)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Binary confusion matrix diagram saved to {output_path}")

def test_department_assignment():
    """Test rule-based department assignment algorithm"""
    print_section_header("4.1.1 RULE-BASED DEPARTMENT ASSIGNMENT TESTING")
    
    test_cases = generate_department_assignment_test_cases()
    results = []
    
    print(f"Testing {len(test_cases)} department assignment cases...")
    
    for idx, test_case in enumerate(test_cases, 1):
        print(f"Test {idx}/{len(test_cases)}: {test_case['symptoms']} (Age: {test_case['age']})", end=' ... ')
        
        # Register patient to test department assignment
        timestamp = int(time.time() * 1000000) + idx
        patient_data = {
            "name": f"Dept Test Patient {idx}",
            "birthday": (datetime.now() - timedelta(days=test_case['age']*365)).strftime('%Y-%m-%d'),
            "age": test_case['age'],
            "sex": "Male" if idx % 2 == 0 else "Female",
            "address": f"Test Address {idx}",
            "contact_no": f"09{(timestamp % 900000000) + 100000000}",
            "email": f"depttest{timestamp}@testclicare.com",
            "emergency_contact_name": "Emergency Contact",
            "emergency_contact_relationship": "Parent",
            "emergency_contact_no": f"09{((timestamp + 1) % 900000000) + 100000000}",
            "symptoms": test_case['symptoms'],
            "duration": "1 week",
            "severity": "Moderate",
            "previous_treatment": "None",
            "allergies": "None",
            "medications": "None"
        }
        
        registration_result = make_api_request("api/patient/register", method="POST", data=patient_data)
        
        if registration_result and registration_result.get('success'):
            predicted = registration_result.get('recommendedDepartment', 'Unknown')
            expected = test_case['expected']
            is_correct = predicted == expected
            
            if is_correct:
                print("‚úÖ PASS")
            else:
                print(f"‚ùå FAIL (Expected: {expected}, Got: {predicted})")
            
            results.append({
                'test_case': idx,
                'symptoms': ', '.join(test_case['symptoms']),
                'age': test_case['age'],
                'category': test_case['category'],
                'expected_department': expected,
                'predicted_department': predicted,
                'correct': is_correct,
                'patient_id': registration_result.get('patient', {}).get('patient_id')
            })
        else:
            print("‚ùå API FAIL")
            results.append({
                'test_case': idx,
                'symptoms': ', '.join(test_case['symptoms']),
                'age': test_case['age'],
                'category': test_case['category'],
                'expected_department': test_case['expected'],
                'predicted_department': 'API_ERROR',
                'correct': False,
                'patient_id': None
            })
        
        time.sleep(0.5)
    
    # Calculate metrics
    valid_results = [r for r in results if r['predicted_department'] != 'API_ERROR']
    total_valid = len(valid_results)
    correct_predictions = sum(1 for r in valid_results if r['correct'])
    
    accuracy = (correct_predictions / total_valid * 100) if total_valid > 0 else 0
    
    # Generate confusion matrix
    if valid_results:
        y_true = [r['expected_department'] for r in valid_results]
        y_pred = [r['predicted_department'] for r in valid_results]
        
        # Get unique departments
        departments = sorted(list(set(y_true + y_pred)))
        
        # Create confusion matrix
        cm = confusion_matrix(y_true, y_pred, labels=departments)
        cm_df = pd.DataFrame(cm, index=departments, columns=departments)
        
        # Calculate per-department metrics
        dept_metrics = []
        for i, dept in enumerate(departments):
            tp = cm[i, i]
            fp = cm[:, i].sum() - tp
            fn = cm[i, :].sum() - tp
            tn = cm.sum() - tp - fp - fn
            
            precision = (tp / (tp + fp) * 100) if (tp + fp) > 0 else 0
            recall = (tp / (tp + fn) * 100) if (tp + fn) > 0 else 0
            f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0
            
            dept_metrics.append({
                'department': dept,
                'tp': tp,
                'fp': fp,
                'fn': fn,
                'tn': tn,
                'precision': precision,
                'recall': recall,
                'f1_score': f1
            })
        
        # Calculate overall metrics
        avg_precision = np.mean([m['precision'] for m in dept_metrics])
        avg_recall = np.mean([m['recall'] for m in dept_metrics])
        avg_f1 = np.mean([m['f1_score'] for m in dept_metrics])
        
        # Print statistical computations
        print_statistics_computation(dept_metrics, y_true, y_pred)
    
    # Print results
    print(f"\n{'='*80}")
    print("4.1.1.5 TEST RESULTS SUMMARY")
    print(f"{'='*80}")
    print(f"Total Test Cases: {len(test_cases)}")
    print(f"Valid API Responses: {total_valid}")
    print(f"Correct Predictions: {correct_predictions}")
    print(f"Accuracy: {accuracy:.2f}% (Target: ‚â•85%) {'‚úÖ PASS' if accuracy >= 85 else '‚ùå FAIL'}")
    
    if valid_results:
        print(f"Precision: {avg_precision:.2f}% (Target: ‚â•80%) {'‚úÖ PASS' if avg_precision >= 80 else '‚ùå FAIL'}")
        print(f"Recall: {avg_recall:.2f}% (Target: ‚â•85%) {'‚úÖ PASS' if avg_recall >= 85 else '‚ùå FAIL'}")
        print(f"F1-Score: {avg_f1:.2f}% (Target: ‚â•82%) {'‚úÖ PASS' if avg_f1 >= 82 else '‚ùå FAIL'}")
    
    # Export results
    results_df = pd.DataFrame(results)
    results_df.to_csv(f"{OUTPUT_DIR}/test_cases_results.csv", index=False)
    
    if valid_results:
        cm_df.to_csv(f"{OUTPUT_DIR}/confusion_matrix.csv")
        
        # Create enhanced visualizations
        create_enhanced_confusion_matrix(cm, departments, f"{OUTPUT_DIR}/confusion_matrix_heatmap.png")
        create_binary_confusion_matrix_diagram(f"{OUTPUT_DIR}/confusion_matrix_binary_diagram.png")
        
        # Create metrics summary table
        metrics_summary = pd.DataFrame([{
            'Metric': 'Accuracy',
            'Formula': '(TP + TN) / (TP + TN + FP + FN) √ó 100',
            'Target (%)': '‚â•85',
            'Result (%)': f"{accuracy:.2f}",
            'Interpretation': 'PASS' if accuracy >= 85 else 'FAIL'
        }, {
            'Metric': 'Precision',
            'Formula': 'TP / (TP + FP) √ó 100',
            'Target (%)': '‚â•80',
            'Result (%)': f"{avg_precision:.2f}",
            'Interpretation': 'PASS' if avg_precision >= 80 else 'FAIL'
        }, {
            'Metric': 'Recall',
            'Formula': 'TP / (TP + FN) √ó 100',
            'Target (%)': '‚â•85',
            'Result (%)': f"{avg_recall:.2f}",
            'Interpretation': 'PASS' if avg_recall >= 85 else 'FAIL'
        }, {
            'Metric': 'F1-Score',
            'Formula': '2 √ó (Precision √ó Recall) / (Precision + Recall)',
            'Target (%)': '‚â•82',
            'Result (%)': f"{avg_f1:.2f}",
            'Interpretation': 'PASS' if avg_f1 >= 82 else 'FAIL'
        }])
        
        metrics_summary.to_csv(f"{OUTPUT_DIR}/metrics_summary.csv", index=False)
        
        # Create detailed test cases table for documentation
        test_cases_table = pd.DataFrame([
            {'Test Case No.': 1, 'Input Symptoms': 'Fever (Adult)', 'Expected Department': 'Internal Medicine', 'System Predicted Department': '', 'Result': ''},
            {'Test Case No.': 2, 'Input Symptoms': 'High Blood Pressure', 'Expected Department': 'Internal Medicine', 'System Predicted Department': '', 'Result': ''},
            {'Test Case No.': 3, 'Input Symptoms': 'Fever (Child)', 'Expected Department': 'Pediatrics', 'System Predicted Department': '', 'Result': ''},
            {'Test Case No.': 4, 'Input Symptoms': 'Pregnancy Check-up', 'Expected Department': 'Obstetrics and Gynecology', 'System Predicted Department': '', 'Result': ''},
            {'Test Case No.': 5, 'Input Symptoms': 'Appendicitis', 'Expected Department': 'General Surgery', 'System Predicted Department': '', 'Result': ''},
            {'Test Case No.': 6, 'Input Symptoms': 'Ear Pain', 'Expected Department': 'ENT and Ophthalmology', 'System Predicted Department': '', 'Result': ''},
            {'Test Case No.': 7, 'Input Symptoms': 'Vision Problems', 'Expected Department': 'ENT and Ophthalmology', 'System Predicted Department': '', 'Result': ''},
            {'Test Case No.': 8, 'Input Symptoms': 'Toothache', 'Expected Department': 'Dental', 'System Predicted Department': '', 'Result': ''}
        ])
        
        # Fill in actual results
        for i, result in enumerate(results[:8]):
            if i < len(test_cases_table):
                test_cases_table.loc[i, 'System Predicted Department'] = result['predicted_department']
                test_cases_table.loc[i, 'Result'] = 'PASS' if result['correct'] else 'FAIL'
        
        test_cases_table.to_csv(f"{OUTPUT_DIR}/test_cases_table.csv", index=False)
        
        # Create department-wise performance analysis
        dept_performance = pd.DataFrame(dept_metrics)
        dept_performance.to_csv(f"{OUTPUT_DIR}/department_performance.csv", index=False)
    
    return {
        'accuracy': accuracy,
        'precision': avg_precision if valid_results else 0,
        'recall': avg_recall if valid_results else 0,
        'f1_score': avg_f1 if valid_results else 0,
        'total_cases': len(test_cases),
        'valid_cases': total_valid,
        'correct_predictions': correct_predictions
    }

def create_department_visualizations(dept_results, results_df):
    """Create department assignment performance visualization charts"""
    
    # Set up the plotting style
    plt.style.use('default')
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. Department Assignment Metrics
    dept_metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    dept_values = [dept_results['accuracy'], dept_results['precision'], dept_results['recall'], dept_results['f1_score']]
    dept_targets = [85, 80, 85, 82]
    
    x_pos = np.arange(len(dept_metrics))
    bars1 = ax1.bar(x_pos, dept_values, alpha=0.8, color='#4DB6AC', label='Actual')
    ax1.plot(x_pos, dept_targets, 'ro-', label='Target', linewidth=2)
    ax1.set_xlabel('Metrics', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')
    ax1.set_title('Department Assignment Performance', fontsize=14, fontweight='bold')
    ax1.set_xticks(x_pos)
    ax1.set_xticklabels(dept_metrics, rotation=45)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar, value in zip(bars1, dept_values):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # 2. Performance by Department
    dept_accuracy = results_df.groupby('expected_department')['correct'].mean() * 100
    dept_accuracy = dept_accuracy.sort_values(ascending=False)
    
    bars2 = ax2.bar(range(len(dept_accuracy)), dept_accuracy.values, alpha=0.8, color='#80CBC4')
    ax2.axhline(y=85, color='red', linestyle='--', label='Target (85%)', linewidth=2)
    ax2.set_xlabel('Department', fontsize=12, fontweight='bold')
    ax2.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
    ax2.set_title('Accuracy by Department', fontsize=14, fontweight='bold')
    ax2.set_xticks(range(len(dept_accuracy)))
    ax2.set_xticklabels(dept_accuracy.index, rotation=45, ha='right')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar, value in zip(bars2, dept_accuracy.values):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # 3. Performance by Category
    category_accuracy = results_df.groupby('category')['correct'].mean() * 100
    category_accuracy = category_accuracy.sort_values(ascending=False)
    
    bars3 = ax3.bar(range(len(category_accuracy)), category_accuracy.values, alpha=0.8, color='#B2DFDB')
    ax3.axhline(y=85, color='red', linestyle='--', label='Target (85%)', linewidth=2)
    ax3.set_xlabel('Category', fontsize=12, fontweight='bold')
    ax3.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
    ax3.set_title('Accuracy by Symptom Category', fontsize=14, fontweight='bold')
    ax3.set_xticks(range(len(category_accuracy)))
    ax3.set_xticklabels(category_accuracy.index, rotation=45, ha='right')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar, value in zip(bars3, category_accuracy.values):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # 4. Overall System Health Gauge
    overall_score = np.mean([dept_results['accuracy'], dept_results['precision'], 
                            dept_results['recall'], dept_results['f1_score']])
    
    # Create a gauge-like visualization
    theta = np.linspace(0, np.pi, 100)
    r = np.ones_like(theta)
    
    ax4.plot(theta, r, 'k-', linewidth=3)
    ax4.fill_between(theta, 0, r, alpha=0.2, color='lightgray')
    
    # Color zones
    if overall_score >= 85:
        color = '#26A69A'
        zone = 'Excellent'
    elif overall_score >= 80:
        color = '#4DB6AC'
        zone = 'Good'
    elif overall_score >= 75:
        color = '#80CBC4'
        zone = 'Fair'
    else:
        color = '#B2DFDB'
        zone = 'Poor'
    
    # Add score indicator
    score_angle = (overall_score / 100) * np.pi
    ax4.plot([score_angle, score_angle], [0, 1], color=color, linewidth=6)
    ax4.text(np.pi/2, 0.5, f'{overall_score:.1f}%\n{zone}', 
             ha='center', va='center', fontsize=18, fontweight='bold')
    ax4.set_xlim(0, np.pi)
    ax4.set_ylim(0, 1.2)
    ax4.set_title('Overall System Health', fontsize=14, fontweight='bold')
    ax4.axis('off')
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/department_assignment_visualization.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"‚úÖ Department assignment visualization saved to {OUTPUT_DIR}/department_assignment_visualization.png")

def generate_department_report(dept_results):
    """Generate comprehensive department assignment report"""
    print_section_header("DEPARTMENT ASSIGNMENT COMPREHENSIVE REPORT")
    
    # Calculate overall system performance
    total_metrics = 4  # Total number of key metrics
    passed_metrics = 0
    
    # Count passed metrics
    if dept_results['accuracy'] >= 85: passed_metrics += 1
    if dept_results['precision'] >= 80: passed_metrics += 1
    if dept_results['recall'] >= 85: passed_metrics += 1
    if dept_results['f1_score'] >= 82: passed_metrics += 1
    
    overall_pass_rate = (passed_metrics / total_metrics * 100)
    
    # Create executive summary
    executive_summary = {
        'test_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'department_assignment': {
            'accuracy': dept_results['accuracy'],
            'precision': dept_results['precision'],
            'recall': dept_results['recall'],
            'f1_score': dept_results['f1_score'],
            'total_cases': dept_results['total_cases'],
            'valid_cases': dept_results['valid_cases'],
            'correct_predictions': dept_results['correct_predictions'],
            'status': 'PASS' if overall_pass_rate >= 80 else 'FAIL'
        },
        'overall_performance': {
            'passed_metrics': passed_metrics,
            'total_metrics': total_metrics,
            'pass_rate': overall_pass_rate,
            'status': 'PASS' if overall_pass_rate >= 80 else 'FAIL'
        }
    }
    
    # Export executive summary
    with open(f"{OUTPUT_DIR}/department_executive_summary.json", 'w') as f:
        json.dump(executive_summary, f, indent=2)
    
    # Print final report
    print(f"\n{'='*80}")
    print("DEPARTMENT ASSIGNMENT - FINAL TEST RESULTS SUMMARY")
    print(f"{'='*80}")
    print(f"Test Date: {executive_summary['test_date']}")
    print(f"Total Test Cases: {executive_summary['department_assignment']['total_cases']}")
    print(f"Valid API Responses: {executive_summary['department_assignment']['valid_cases']}")
    print(f"Correct Predictions: {executive_summary['department_assignment']['correct_predictions']}")
    print(f"\nüìä DEPARTMENT ASSIGNMENT RESULTS:")
    print(f"  Accuracy: {executive_summary['department_assignment']['accuracy']:.2f}% (Target: ‚â•85%)")
    print(f"  Precision: {executive_summary['department_assignment']['precision']:.2f}% (Target: ‚â•80%)")
    print(f"  Recall: {executive_summary['department_assignment']['recall']:.2f}% (Target: ‚â•85%)")
    print(f"  F1-Score: {executive_summary['department_assignment']['f1_score']:.2f}% (Target: ‚â•82%)")
    print(f"\nüéØ OVERALL SYSTEM PERFORMANCE:")
    print(f"  Metrics Passed: {executive_summary['overall_performance']['passed_metrics']}/{executive_summary['overall_performance']['total_metrics']}")
    print(f"  Overall Pass Rate: {executive_summary['overall_performance']['pass_rate']:.2f}%")
    print(f"  System Status: {executive_summary['overall_performance']['status']}")
    
    return executive_summary

def cleanup_department_test_data():
    """Clean up department assignment test data from database"""
    print("\nüßπ Cleaning up department assignment test data...")
    
    cleanup_sql = """
-- Clean up department assignment test patients
DELETE FROM queue WHERE visit_id IN (
    SELECT visit_id FROM visit WHERE patient_id IN (
        SELECT id FROM outpatient WHERE name LIKE '%Dept Test Patient%'
    )
);

DELETE FROM visit WHERE patient_id IN (
    SELECT id FROM outpatient WHERE name LIKE '%Dept Test Patient%'
);

DELETE FROM emergency_contact WHERE patient_id IN (
    SELECT id FROM outpatient WHERE name LIKE '%Dept Test Patient%'
);

DELETE FROM outpatient WHERE name LIKE '%Dept Test Patient%';
"""
    
    with open(f"{OUTPUT_DIR}/department_cleanup_sql.sql", 'w') as f:
        f.write(cleanup_sql)
    
    print(f"‚úÖ Department assignment cleanup SQL saved to {OUTPUT_DIR}/department_cleanup_sql.sql")
    print("üí° Run the SQL commands to clean up test data from your database")

def run_comprehensive_department_tests():
    """Run all department assignment tests"""
    
    print("\n" + "="*80)
    print("CLICARE OBJECTIVE 1 - DEPARTMENT ASSIGNMENT COMPREHENSIVE TESTING")
    print("="*80)
    print(f"Testing against: {API_BASE}")
    print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Output directory: {OUTPUT_DIR}")
    
    # Create output directories
    create_output_directory()
    
    # Check backend connectivity
    print("\nüîç Checking backend connectivity...")
    health_check = make_api_request("api/health")
    if not health_check:
        print("‚ùå Backend not reachable. Please ensure your server is running.")
        return
    
    print(f"‚úÖ Backend is online: {health_check.get('message', 'OK')}")
    
    try:
        print("\nüöÄ Starting department assignment testing...")
        
        # Run department assignment tests
        dept_results = test_department_assignment()
        
        # Load results for visualization
        results_df = pd.read_csv(f"{OUTPUT_DIR}/test_cases_results.csv")
        
        # Generate comprehensive report
        final_report = generate_department_report(dept_results)
        
        # Generate visualization
        try:
            create_department_visualizations(dept_results, results_df)
        except Exception as e:
            print(f"‚ö†Ô∏è Visualization generation failed: {e}")
        
        # Print completion message
        print(f"\n{'='*80}")
        print("‚úÖ DEPARTMENT ASSIGNMENT TESTS COMPLETED SUCCESSFULLY")
        print(f"{'='*80}")
        print(f"\nüìä Final Results Summary:")
        print(f"   ‚Ä¢ Overall Pass Rate: {final_report['overall_performance']['pass_rate']:.2f}%")
        print(f"   ‚Ä¢ System Status: {final_report['overall_performance']['status']}")
        print(f"\nüìÅ All results saved to: {OUTPUT_DIR}/")
        print(f"   ‚Ä¢ Test Results: {OUTPUT_DIR}/test_cases_results.csv")
        print(f"   ‚Ä¢ Confusion Matrix CSV: {OUTPUT_DIR}/confusion_matrix.csv")
        print(f"   ‚Ä¢ Confusion Matrix Heatmap: {OUTPUT_DIR}/confusion_matrix_heatmap.png")
        print(f"   ‚Ä¢ Binary Confusion Matrix: {OUTPUT_DIR}/confusion_matrix_binary_diagram.png")
        print(f"   ‚Ä¢ Metrics Summary: {OUTPUT_DIR}/metrics_summary.csv")
        print(f"   ‚Ä¢ Executive Summary: {OUTPUT_DIR}/department_executive_summary.json")
        print(f"   ‚Ä¢ Performance Chart: {OUTPUT_DIR}/department_assignment_visualization.png")
        print(f"   ‚Ä¢ Department Performance: {OUTPUT_DIR}/department_performance.csv")
        
        print(f"\nüìã Documentation Tables Generated:")
        print(f"   ‚Ä¢ Table 4.1.1.3: Confusion Matrix for Department Assignment")
        print(f"   ‚Ä¢ Table 4.1.1.4: Test Cases for Department Assignment")
        print(f"   ‚Ä¢ Table 4.1.1.5: Test Results for Department Assignment")
        print(f"   ‚Ä¢ Department-wise Performance Analysis")
        print(f"   ‚Ä¢ Statistical Computations with Formulas")
        
        print(f"\nüí° Next Steps:")
        print(f"   1. Review confusion_matrix_heatmap.png for visual analysis")
        print(f"   2. Check confusion_matrix_binary_diagram.png for 2x2 matrix explanation")
        print(f"   3. Review department_performance.csv for per-department metrics")
        print(f"   4. Check performance visualization for overall charts")
        print(f"   5. Use data for research documentation")
        print(f"   6. Clean up test data from database if needed")
        
        if CLEANUP_AFTER_TEST:
            cleanup_department_test_data()
        
        return final_report
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Testing interrupted by user")
        return None
    except Exception as e:
        print(f"\n\n‚ùå Error during testing: {e}")
        import traceback
        traceback.print_exc()
        return None

# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    try:
        print("\n" + "="*80)
        print("CLICARE OBJECTIVE 1 - DEPARTMENT ASSIGNMENT COMPREHENSIVE TESTING")
        print("WITH ENHANCED VISUALIZATIONS AND STATISTICAL COMPUTATIONS")
        print("="*80)
        print("\nüìã This comprehensive test suite will:")
        print("   ‚úì Test Rule-Based Department Assignment Algorithm")
        print("   ‚úì Test against REAL backend API and database")
        print("   ‚úì Generate comprehensive confusion matrices")
        print("   ‚úì Create enhanced confusion matrix visualizations (matching uploaded image)")
        print("   ‚úì Display detailed statistical computations with formulas")
        print("   ‚úì Calculate accuracy, precision, recall, F1-score")
        print("   ‚úì Test all 15 departments with multiple scenarios")
        print("   ‚úì Generate performance visualizations")
        print("   ‚úì Export all required tables and documentation")
        
        print(f"\nüìä Test Coverage:")
        print(f"   ‚Ä¢ ENT and Ophthalmology: 5 test cases")
        print(f"   ‚Ä¢ Obstetrics and Gynecology: 4 test cases")
        print(f"   ‚Ä¢ General Surgery: 4 test cases")
        print(f"   ‚Ä¢ Pediatrics: 4 test cases")
        print(f"   ‚Ä¢ Family Medicine Regular: 5 test cases")
        print(f"   ‚Ä¢ Family Medicine Senior/PWD: 3 test cases")
        print(f"   ‚Ä¢ Internal Medicine: 5 test cases")
        print(f"   ‚Ä¢ TB DOTS: 3 test cases")
        print(f"   ‚Ä¢ Dental: 4 test cases")
        print(f"   ‚Ä¢ Diabetes Clinic: 2 test cases")
        print(f"   ‚Ä¢ Cardiology: 3 test cases")
        print(f"   ‚Ä¢ Nephrology Adult: 2 test cases")
        print(f"   ‚Ä¢ Pulmonology Adult: 2 test cases")
        print(f"   ‚Ä¢ Neurology: 2 test cases")
        print(f"   ‚Ä¢ Gastroenterology Adult: 2 test cases")
        print(f"   ‚Ä¢ Total: 50 comprehensive test cases")
        
        print(f"\nüéØ Target Metrics:")
        print(f"   ‚Ä¢ Accuracy: ‚â•85%")
        print(f"   ‚Ä¢ Precision: ‚â•80%")
        print(f"   ‚Ä¢ Recall: ‚â•85%")
        print(f"   ‚Ä¢ F1-Score: ‚â•82%")
        
        print(f"\nüé® Enhanced Features:")
        print(f"   ‚Ä¢ Confusion matrix with teal color scheme (matching your image)")
        print(f"   ‚Ä¢ Binary 2x2 confusion matrix diagram")
        print(f"   ‚Ä¢ Detailed statistical computations displayed in console")
        print(f"   ‚Ä¢ Formula explanations for all metrics")
        print(f"   ‚Ä¢ Per-department breakdown with TP/FP/FN/TN values")
        
        if CLEANUP_AFTER_TEST:
            print("\n‚ö†Ô∏è  Note: Test data will be created in your database.")
            print("   Cleanup SQL will be provided after testing.")
        
        print("\n" + "="*80)
        input("Press ENTER to start department assignment testing (or Ctrl+C to cancel)...")
        
        # Run comprehensive tests
        final_report = run_comprehensive_department_tests()
        
        if final_report:
            print("\n" + "="*80)
            print("‚úÖ DEPARTMENT ASSIGNMENT TESTING COMPLETED SUCCESSFULLY")
            print("="*80)
            print(f"\nüéØ FINAL RESULTS:")
            print(f"   ‚Ä¢ Overall System Pass Rate: {final_report['overall_performance']['pass_rate']:.2f}%")
            print(f"   ‚Ä¢ Department Assignment Status: {final_report['department_assignment']['status']}")
            
            print(f"\nüìÅ Complete Documentation Package:")
            print(f"   ‚Ä¢ All test results: {OUTPUT_DIR}/")
            print(f"   ‚Ä¢ Confusion matrices: CSV + PNG visualizations")
            print(f"   ‚Ä¢ Performance metrics: All required tables generated")
            print(f"   ‚Ä¢ Visualizations: Charts and graphs included")
            print(f"   ‚Ä¢ Statistical computations: Displayed in console output")
            
            print(f"\nüí° Research Documentation Ready:")
            print(f"   ‚Ä¢ Table 4.1.1.3: {OUTPUT_DIR}/confusion_matrix.csv")
            print(f"   ‚Ä¢ Confusion Matrix Heatmap: {OUTPUT_DIR}/confusion_matrix_heatmap.png")
            print(f"   ‚Ä¢ Binary Matrix Diagram: {OUTPUT_DIR}/confusion_matrix_binary_diagram.png")
            print(f"   ‚Ä¢ Table 4.1.1.4: {OUTPUT_DIR}/test_cases_table.csv")
            print(f"   ‚Ä¢ Table 4.1.1.5: {OUTPUT_DIR}/metrics_summary.csv")
            print(f"   ‚Ä¢ Department Performance: {OUTPUT_DIR}/department_performance.csv")
            print(f"   ‚Ä¢ Performance Chart: {OUTPUT_DIR}/department_assignment_visualization.png")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Testing interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Fatal error during testing: {e}")
        import traceback
        traceback.print_exc()
        print("\nüí° Common issues:")
        print("   ‚Ä¢ Ensure backend server is running (node server.js)")
        print("   ‚Ä¢ Check database connectivity")
        print("   ‚Ä¢ Verify API endpoints are accessible")
        print("   ‚Ä¢ Close any CSV files that might be open")